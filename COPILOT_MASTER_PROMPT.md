# ü§ñ MASTER GITHUB COPILOT AGENT PROMPT
## Adaptive Data Governance Framework - Complete Implementation

### üéØ OBJECTIVE
Build a production-ready, end-to-end **Adaptive Data Governance Framework** for E-Commerce platforms using PySpark, Delta Lake, and AI-powered PII detection. This is a dissertation-grade implementation requiring enterprise architecture patterns.

---

### üìã PROJECT CONTEXT
**Domain:** Data Governance & Big Data Engineering
**Use Case:** DPDP Act 2023 compliant E-Commerce data processing
**Architecture:** Medallion (Bronze-Silver-Gold) + AI PII Detection + Airflow Orchestration
**Scale:** Handles 100M+ records, petabyte-ready
**Deployment:** Dockerized Spark cluster (1 master + 2 workers)

---

### üèóÔ∏è IMPLEMENTATION REQUIREMENTS

#### 1. DATA INGESTION LAYER (`src/ingestion/`)

**File:** `data_loader.py`
- Multi-source data ingestion with schema inference and Delta Lake integration.
- Support for: CSV, Parquet, JSON.
- Incremental loading with watermark tracking.
- Auto-detect schema drift and log to Delta Lake transaction log.

**File:** `schema_registry.py`
- Schema versioning and registration.
- Drift comparison between incoming vs. existing schema.

#### 2. PII DETECTION ENGINE (`src/pii_detection/`)

**File:** `pii_detector.py`
- Transformer-based NER model (DistilBERT) for detecting PII in unstructured text.
- Fine-tuned for: EMAIL, PHONE, AADHAAR, PAN, CREDIT_CARD.
- Operates as Spark UDF for distributed processing.
- Confidence scoring with configurable threshold.

**File:** `pii_masker.py`
- Masking strategies: HASH (SHA-256), REDACT (***), TOKENIZE (format-preserving).
- Maintain referential integrity through consistent hashing.

**File:** `train_ner_model.py`
- Fine-tuning script for DistilBERT NER model on synthetic Indian PII data.
- BIO labelling scheme with HuggingFace Trainer API.

#### 3. DATA TRANSFORMATION LAYER (`src/transformation/`)

**File:** `bronze_to_silver.py`
- Deduplication via window functions.
- Great Expectations validation suite.
- PII masking UDFs.
- Data lineage metadata.

**File:** `silver_to_gold.py`
- Pre-aggregated metrics: revenue (daily/weekly/monthly), CLV, RFM segmentation.
- Broadcast joins for dimension tables.

**File:** `scd_manager.py`
- SCD Type 2 via Delta Lake MERGE.
- Hash-based change detection, version tracking.

#### 4. DATA QUALITY FRAMEWORK (`src/quality/`)

**File:** `data_quality_engine.py`
- Great Expectations suite builder from schema dict.
- Validate DataFrames with pass/fail gating.

**File:** `quality_metrics.py`
- Six dimensions: completeness, uniqueness, validity, timeliness, consistency, accuracy.
- Configurable weights with overall score computation.

#### 5. ORCHESTRATION (`airflow/dags/`)

**File:** `medallion_pipeline_dag.py`
- Daily DAG: generate ‚Üí ingest ‚Üí transform ‚Üí quality gate ‚Üí aggregate.
- Retry logic with exponential backoff, SLA monitoring (< 2 hours).

**File:** `pii_audit_dag.py`
- Weekly PII compliance audit scanning all Silver tables.

#### 6. UTILITY MODULES (`src/utils/`)

- `spark_utils.py` ‚Äî Spark session factory with Delta Lake configuration.
- `config_loader.py` ‚Äî YAML config loading with Pydantic validation.
- `logger.py` ‚Äî Structured JSON logging with correlation IDs (Loguru).
- `data_generator.py` ‚Äî Synthetic Indian e-commerce data (Faker); 5% nulls, 2% schema drift, PII injection.
- `roi_calculator.py` ‚Äî Financial ROI calculator for governance investment.

---

### üîß TECHNICAL SPECIFICATIONS

#### Spark Configuration
```python
spark = SparkSession.builder \
    .appName("AdaptiveGovernance") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .config("spark.sql.shuffle.partitions", "200") \
    .config("spark.databricks.delta.retentionDurationCheck.enabled", "false") \
    .config("spark.databricks.delta.properties.defaults.autoOptimize.optimizeWrite", "true") \
    .getOrCreate()
```

#### Delta Lake Schema Evolution
```python
df.write.format("delta") \
    .mode("append") \
    .option("mergeSchema", "true") \
    .option("optimizeWrite", "true") \
    .save("/path/to/delta/table")
```

---

### üìä DELIVERABLES

```
adaptive-governance-framework/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ COPILOT_MASTER_PROMPT.md
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile.jupyter
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema_registry.py
‚îÇ   ‚îú‚îÄ‚îÄ pii_detection/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pii_detector.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pii_masker.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_ner_model.py
‚îÇ   ‚îú‚îÄ‚îÄ transformation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bronze_to_silver.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ silver_to_gold.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scd_manager.py
‚îÇ   ‚îú‚îÄ‚îÄ quality/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_quality_engine.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_metrics.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ spark_utils.py
‚îÇ       ‚îú‚îÄ‚îÄ config_loader.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py
‚îÇ       ‚îú‚îÄ‚îÄ data_generator.py
‚îÇ       ‚îî‚îÄ‚îÄ roi_calculator.py
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îî‚îÄ‚îÄ dags/
‚îÇ       ‚îú‚îÄ‚îÄ medallion_pipeline_dag.py
‚îÇ       ‚îî‚îÄ‚îÄ pii_audit_dag.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_pii_detection.py
‚îÇ   ‚îú‚îÄ‚îÄ test_data_quality.py
‚îÇ   ‚îî‚îÄ‚îÄ test_medallion_pipeline.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh
‚îÇ   ‚îú‚îÄ‚îÄ download_data.sh
‚îÇ   ‚îî‚îÄ‚îÄ benchmark.py
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_pii_model_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_dq_analysis.ipynb
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ architecture.md
    ‚îú‚îÄ‚îÄ api_reference.md
    ‚îú‚îÄ‚îÄ deployment_guide.md
    ‚îî‚îÄ‚îÄ dpdp_compliance.md
```

---

### üöÄ VALIDATION CRITERIA

**Success Metrics:**
- ‚úÖ All Docker containers start successfully
- ‚úÖ Spark UI accessible at http://localhost:8080
- ‚úÖ Airflow DAG runs without errors
- ‚úÖ PII detection F1-score > 0.92
- ‚úÖ Data quality score > 90% for Silver layer
- ‚úÖ End-to-end pipeline completes in < 2 hours
- ‚úÖ Delta Lake time travel works (audit trail)
- ‚úÖ All tests pass with >80% code coverage

---

### üîê COMPLIANCE CHECKLIST (DPDP Act 2023)

- PII automatically detected and masked
- Consent management flags in customer table
- Data retention policies enforced (7 years)
- Audit logs for all data access
- Right to erasure (delete customer data)
- Encryption at rest (Delta Lake)
- Anonymization for analytics datasets
